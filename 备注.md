# 官方试用链接
https://ragflow.io/

# 分块策略详解
https://zhuanlan.zhihu.com/p/1886359804987036986
- General：无论是 DOCX、PPT 还是 HTML 等多种格式文件，它都能轻松搞定。自动帮你把文本切成合适大小的块，像是给文件做了一个精准的切片，方便后续操作。
- Q&A：要是碰上 excel 文件，两列摆好，问题答案分明；csv/txt 文件，编码和分隔符设置正确，它就能完美适配，让你的问答对轻松对应。
- Resume：简历处理更是不在话下，不管多乱的格式，一键就能结构化，像是给简历施了魔法，关键信息瞬间清晰。
- Manual：针对有分层结构的手册，它按照标题切片，同一部分的内容完整保留，块大小还能自定义，超灵活。
- Table：处理 csv/txt 表格文件，TAB 分隔、列标题明确，还能处理同义词，表格数据立马变得井井有条。
- Paper：论文处理超贴心，按章节切片，既方便理解又能减少计算成本，像是给论文装上了智能导航。
- Book：长篇书籍也不怕，设置好页码范围，负面影响直接消，分析时间大大节省。
- Laws：法律文件的严谨格式它能精准识别，以‘ARTICLE’为单位切片，上下文完整保留，法律条文处理超专业。
- Presentation：PPT 文件每个页面独立成块，缩略图还帮你存好，展示起来超方便。
- One：一个文档就是一个完整块，适合需要总结全文的情况，上下文全保留，总结起来超省心。
- Knowledge Graph：支持多种格式文件，切块后还能提取知识图谱，像是给文件装上了智能大脑，知识关联一目了然。
- Tag：用标签分类文件，查询时带上标签，相关内容轻松定位，文件管理超高效。

# 关于Graph
- 0.16.0版本中对Graph做了如下更新：
  - 关于Graph构造
    - 过去的GraphRAG为每个文档构建一个 Knowledge Graph，而0.16.0版本则为**每一个知识库构建一个Knowledge Graph**。单个文档可选择是否进行 Graph 实体抽取，抽取的Graph 实体会动态更新到知识图谱当中
    - 实体抽取可以有两种模式的选择，Light/General。Light 采用了 香港科大 LightRAG 的实体抽取 prompt，General 则采用了微软 GraphRAG 的 prompt，后者更长，耗费的 token 更多。抽取效果跟大模型和用户的数据相关，用户可以选择对比。
    - 实体去重 （Entity Resolution）变成可选项。在 0.9.0 版本引入的 GraphRAG 中，实体去重是内置的，在某些情况下，它确实提高了知识图谱的质量，但也增加了 token 消耗。在 GraphRAG 中，自动构造的知识图谱，通常无法达到数据可视化的要求，因此一般是作为辅助召回存在，所以把实体去重作为可选项，可以让用户来在知识图谱的质量和成本之间作出选择。
    - 社区摘要变成可选项。在微软的标准 GraphRAG 中， 社区摘要是一个必选项，它提升了辅助召回的问答质量，但也是 token 消耗的重要来源之一，因此变成可选项，可以让用户在效果和成本中作出选择。
  - 关于Graph召回
    - 查询时可以勾选是否需要提取知识图谱相关信息。如果勾选，查询过程变成了：
      1. 利用大模型对问题进行分析，提取相关的实体1和实体类型。
      2. 用相关的实体类型在知识图谱中做 PageRank 计算（随机游走），得到 PageRank 值前 N 的实体及其描述。
      3. 通过实体1的向量相似度召回相似实体及其描述，以及 N-hop 的实体关系。
      4. 通过原问题用向量相似度召回实体关系及其描述。
      5. 对实体和实体关系进行排序。排序理论支撑贝叶斯，P(E|Q) => P(E) * P(Q|E)，实体或关系本身的 PageRank 值乘以实体或关系和 Query/Question 的相似度。
      6. 用相关的实体召回 Top 1 社区摘要。
      7. 将实体和关系描述以及社区摘要报告作为 prompt 扔给大模型。
     
- RAGFlow中的Graph工作过程
  https://pic1.zhimg.com/v2-432dc724bff37ccb2f9a4d7e4fdfe5b6_1440w.jpg


  Graph构建入口：graphrag/general/index.py 的 run_graphrag()。过程是：
  1. 基于文档分片构建知识图谱，包括实体和关系的抽取，以及知识图谱的生成；
  2. 知识图谱合并，将新生成的知识图谱与原有知识图谱进行合并；
  3. 知识图谱的实体合并，减少实体重复，提升准确性；
  4. 基于知识图谱构建社区，包括社区构建与摘要生成；

 ## 关于实体抽取
  RAGFlow的Graph支持两种实体和关系提取方式：
  - Light：港大的LightRAG方式
  - General：微软的GraphRAG方式。
  两者区别影响的就是这部分抽取的prompt。
  1. General的实现方式
     - 通过精心设计的 prompt 和 Few-Shot 机制，利用大模型完成实体和关系的抽取。
     - graphrag/general/graph_extractor.py 中的 _process_single_content() 方法中完成
    
## 关于图谱生成与图谱合并
1. 图谱生成
  基于 networkx 生成知识图谱。调用 networkx 的 add_node() 和 add_edge() 方法实现，具体实现可参考 graphrag/general/index.py 中的 generate_subgraph() 方法。
2. 图谱合并
  graph_merge() 中完成，处理逻辑如下：
  - 节点存在时，将新节点的描述信息叠加至原有节点；
  - 关系存在时，将新关系的描述信息、权重和关键词叠加至原有关系；

## 关于实体合并
RagFlow 在 graphrag/entity_resolution.py 中实现实体合并。两步策略：
1. 初步相似度判断：使用编辑距离等工程手段筛选相似实体，基于 editdistance 实现；
2. 大模型相似度判断：确定最终的实体合并结果；

## 关于社区构建
社区构建基于 Leiden 算法实现，该算法通过模块度优化生成高质量的社区划分。实现位于 graphrag/general/leiden.py。
技术参考论文：https://arxiv.org/pdf/2404.16130
社区构建基于 graspologic 的 hierarchical_leiden 实现。

1. 社区摘要
社区摘要生成基于社区中实体和关系的描述信息，完全依赖大模型实现。通过精心设计的 prompt，生成能够代表社区核心内容的文本，提升检索和召回准确性。
相关 prompt 在 graphrag/general/community_report_prompt.py 中定义 

## 关于Graph的检索策略
graphrag/search.py 中实现。具体步骤：
1. 查询重写：调用 query_rewrite 方法，使用大模型提取问题中的实体类型关键词和实体；
2. 实体与关系检索：通过关键词和实体类型检索相关实体，通过原始问题检索相关关系；
3. 路径分析：从关键词检索到的实体出发，获取 N 跳邻居，实现相似度衰减；
3. 结果融合与评分：融合关键词检索、实体类型检索和关系检索结果，确定最终得分；
4. 结果排序与截断：按相似度和 PageRank 乘积排序，截取前 N 个结果；
5. 社区检索：调用 _community_retrival_() 方法检索相关社区报告；
6. 结果组合：将实体、关系和社区报告组合为最终结果；
         
# 关于标签
  - 标签库在 RAGFlow 中也作为知识库存在。需要上传标签文件，上传时Chunk选择TAG。
  - 支持标签可视化
  - 支持标签修改
  - 支持知识向量时，对业务知识每个Chunk根据标签库内容自动打标签。具体算法是利用 Chunk 和标签库文件的 Description/Question 字段文本的相似度，如果该相似度达到阈值，那么该 Chunk 就被打上 Tag 字段的各标签。
  - 在查询时，Query也会被自动打上不同权重的标签，计算方法跟上述类似，这样在排序阶段，包含相关标签的 Chunk 就会得到加权。

# 关于RAPTOR
https://arxiv.org/html/2401.18059v1
RAPTOR（用于树状组织检索的递归抽象处理）是一种增强型文档预处理技术，于2024年的一篇论文中提出。RAPTOR 旨在解决多跳问答问题，它对文档块执行递归聚类和摘要，以构建分层树状结构。
我们采用这种新方法进行的测试，在需要复杂、多步骤推理的问答任务中展现了最佳 (SOTA) 效果。通过将 RAPTOR 检索与我们内置的分块方法和/或其他检索增强生成 (RAG) 方法相结合，您可以进一步提升问答准确率。

过程是：将原始文档划分为多个块后，这些块将根据语义相似性（而非其在文本中的原始顺序）进行聚类。然后，系统默认的聊天模型会将聚类结果汇总为更高级别的块。此过程以递归方式应用，形成一个自下而上具有不同汇总级别的树形结构。如下图所示，初始块构成叶节点（以蓝色显示），并被递归汇总为根节点（以橙色显示）。
递归聚类和总结捕获了多跳问答所需的广泛理解（通过根节点）以及精细细节（通过叶节点）

# 其它弥补语音鸿沟的方法
  - RAPTOR，GraphRAG，Contextual Retrieval、标签

# 关于DeepDoc
在RAGFlow中，DeepDoc只用于PDF文档解析。
DeepDoc 是一个基于人工智能的文档智能分析平台，主要用于自动化处理和理解复杂的非结构化文档（如PDF、扫描件、合同、财务报表等）。它利用自然语言处理（NLP）、计算机视觉（OCR）和深度学习技术，从文档中提取关键信息、识别语义结构，并支持智能审核、数据录入自动化等应用场景。
主要功能可能包括：
高精度 OCR（光学字符识别），尤其适用于模糊或复杂版式文档
表格、段落、标题等结构化信息识别
合同条款抽取与比对
自动生成摘要或问答
支持多语言文档处理
这类系统常见于金融、法律、医疗、政务等领域，用于提升文档处理效率。

# 关于文档解析
文件解析通过接口 /v1/document/run。
api/db/services/task_service.py 中的 queue_tasks() 中完成的，此方法会根据文件创建一个或多个异步任务，方便异步执行。
文件的解析是根据内容拆分为多个任务，通过 Redis 消息队列进行暂存，之后就可以离线异步处理。

消息队列的消费模块，对应在 rag/svr/task_executor.py 中的 main() 方法中。
1. 调用 collect() 方法从消息队列中获取任务
2. 接下来每个任务会依次调用 build() 进行文件的解析
   - 根据 parser_id 去选择合适的解析器组，注意这个应该是从业务层得到的一个类型，每个解析器组中都包含了 pdf, word 等支持格式的文件解析
4. 调用 embedding() 方法进行向量化
5. 最后调用 ELASTICSEARCH.bulk() 写入 ElasticSearch，从这里就可以看到向量库的技术选型

文档预处理：
包含了不少了数据的清理操作，比如在 deepdoc/vision/layout_recognizer.py。

